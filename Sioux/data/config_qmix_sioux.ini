# =============================================================================
# QMIX Configuration File for Multi-Agent Traffic Signal Control
# =============================================================================
# This configuration file defines all hyperparameters for the QMIX training.
# Modify these values to experiment with different training strategies.

[NETWORK_CONFIG]
# Architecture parameters for QMIX neural networks
agent_hidden_dim = 64           # Feed-forward hidden layer dimension
agent_rnn_hidden_dim = 64       # GRU hidden state dimension for temporal memory
mixing_embed_dim = 32           # Embedding dimension for value mixing
hypernet_embed_dim = 64         # Hypernetwork embedding dimension

[TRAINING_CONFIG]
# QMIX algorithm hyperparameters
learning_rate = 5e-4            # Adam optimizer learning rate
discount_factor = 0.99          # Gamma - future reward discounting
target_update_freq = 200        # Update target network every N gradient steps
grad_clip = 10.0                # Gradient clipping maximum norm

# Epsilon-greedy exploration
epsilon_start = 1.0             # Initial exploration probability
epsilon_min = 0.05              # Minimum exploration probability
epsilon_decay = 0.995           # Exponential decay factor per episode

# Training dynamics
batch_size = 32                 # Mini-batch size for gradient updates
replay_buffer_capacity = 5000   # Maximum episodes to store
train_steps_per_episode = 10    # Gradient steps per simulation episode
max_episode_length = 200        # Maximum timesteps per episode

[REWARD_CONFIG]
# Reward shaping parameters
reward_scale = 1.0              # Scale factor for all rewards
queue_weight = 1.0              # Weight for queue length in reward (negative)
flickering_penalty = 0.1        # Penalty for frequent phase changes

# Max Pressure reward components:
# reward = -incoming_queue * queue_weight - flickering_penalty

[SIGNAL_CONFIG]
# Traffic signal timing constraints
min_green_time = 15             # Minimum green phase duration (steps)
max_green_time = 120            # Maximum green phase duration (steps)
yellow_time = 5                 # Yellow phase duration (steps)

[SIMULATION_CONFIG]
# SUMO simulation parameters
sumo_config = ..\Sioux\data\exp_0.sumocfg  # Path to SUMO configuration
use_gui = False                 # Enable SUMO GUI visualization
decision_interval = 2           # Steps between agent decisions
waiting_time_memory = 1000      # SUMO memory window for waiting time

[TRAINING_CONTROL]
# Training and evaluation schedule
num_episodes = 50               # Total training episodes
test_interval = 10              # Evaluate every N episodes
save_checkpoint_interval = 10   # Save model every N episodes
device = cuda                   # 'cuda' for GPU, 'cpu' for CPU

[PATHS]
# Output and checkpoint directories
checkpoint_dir = ./qmix_checkpoints
results_dir = ./qmix_results
log_level = INFO                # Logging level (DEBUG, INFO, WARNING)

# =============================================================================
# PRESET CONFIGURATIONS (Uncomment and modify to switch presets)
# =============================================================================

# [PRESET: FAST_TRAINING]
# Faster training with smaller networks for quick experimentation
# num_episodes = 20
# agent_hidden_dim = 32
# agent_rnn_hidden_dim = 32
# mixing_embed_dim = 16
# batch_size = 16

# [PRESET: SLOW_STABLE]
# Slower but more stable training with larger networks
# num_episodes = 100
# agent_hidden_dim = 128
# agent_rnn_hidden_dim = 128
# mixing_embed_dim = 64
# learning_rate = 1e-4
# epsilon_decay = 0.998

# [PRESET: EXPLORATION_HEAVY]
# Emphasize exploration with higher initial epsilon and slower decay
# epsilon_start = 1.0
# epsilon_min = 0.1
# epsilon_decay = 0.99

# [PRESET: EXPLOITATION_HEAVY]
# Emphasize exploitation with quick epsilon decay
# epsilon_start = 0.5
# epsilon_min = 0.01
# epsilon_decay = 0.95

# =============================================================================
